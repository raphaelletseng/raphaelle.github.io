I"ô<p><em>19th Nov 2021</em> - Edited note: I used the terms â€˜unfairness mitigationâ€™ and â€˜bias mitigationâ€™ interchangably in this report. I think the correct term should be â€˜unfairness mitigationâ€™. In the paper <a href="https://arxiv.org/pdf/2104.12544.pdf">The Myth of Complete AI-Fairness</a>, Virginia Dignum makes the point that not all bias is bad, and bias in human data is impossible to fully eliminate. <strong>â€œBias is not the problem,â€</strong> they write, <strong>â€œprejudice and discrimination are.â€</strong></p>

<blockquote>
  <p>â€œWhereas prejudice represents a preconceived judgment or attitude, discrimination is a behaviour. In society, discrimination is often enacted through institutional structures and policies, and embedded in cultural beliefs and representations, and is thus reflected in any data collected. The focus need be on using AI to support interventions aimed at reducing prejudice and discrimination, e.g. through education, facilitation of intergroup contact, targeting social norms promoting positive relations between groups, or supporting people identify their own bias and prejudices.â€</p>
</blockquote>

<p><br /></p>

<iframe src="/assets/privacy_fairness_Report.pdf" width="100%" height="750px">
</iframe>
:ET